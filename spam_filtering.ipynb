{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filtering with Memory-Based and Naive Bayes models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook has been written as part of the project for the L101 module. It aims at studying Memory-Based and Naive Bayes models for Spam Filtering. It is composed of four parts:\n",
    "- Data pre-processing: multiple steps of pre-processing on the train set\n",
    "- Adaptation set pre-processing\n",
    "- Test set pre-processing\n",
    "- Naive Bayes models: apply Naive Bayes models to the data pre-processed previously  \n",
    "\n",
    "\n",
    "Memory-Based models are run thanks to TiMBL Software (Daelemans et al., 2000). To do so, we run in our console the command line: `timbl -f data_timbl/data_700.train -t data_timbl/data_700.test -wgr -dID -k1 +vcs`  \n",
    "This commmand line is composed of the following arguments:\n",
    "- `-f`: file with the train set in the C4.5 format (see Section 2.2 in the report)\n",
    "- `-t`: file with the adaptation/test set in the C4.5 format\n",
    "- `-w`: feature-weighting scheme (gr: Gain Ratio, 0: Equal Weights)\n",
    "- `-d`: distance-weighting scheme (z: Equal Distance, ID: Inverse Distance, IL: Inverse Linear, ED: Exponential Decay)\n",
    "- `+v`: output format (cs: class statistics with precision, recall, f1-score and AUC metrics)  \n",
    "\n",
    "\n",
    "Models and parameters selection are carried out with the train and adaptation sets, while methods comparison is realised with the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wIKNkiGUVCn",
    "outputId": "8ad49b33-db83-475a-9588-dc5cf50b4631"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup \n",
    "import nltk\n",
    "import heapq\n",
    "from info_gain import info_gain\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1r_LRKIUVCw"
   },
   "source": [
    "### Data reading and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read XML files containing messages and transform them into a dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4M_3ARR1UVCx"
   },
   "outputs": [],
   "source": [
    "def xml_to_df(file_path):\n",
    "    file = open(file_path,\"rb\")\n",
    "    data = BeautifulSoup(file)\n",
    "    data = data.find_all('message')\n",
    "    df = pd.DataFrame()\n",
    "    for msg in data:\n",
    "        tag_dict = {}\n",
    "        for tag in msg.children:\n",
    "            if tag.name is not None:\n",
    "                if tag.text_normal is None:\n",
    "                    tag_dict[tag.name] = [tag.string]\n",
    "                else:\n",
    "                    tmp = tag.find_all(\"text_normal\")\n",
    "                    text_normal = \"\"\n",
    "                    for i in range(len(tmp)-1):\n",
    "                        tag_dict[tag.name + \"_normal_\" + str(i)] = tmp[i].get_text().replace(tmp[i+1].get_text(),'')\n",
    "                        text_normal += \"\\n\" + tag_dict[tag.name + \"_normal_\" + str(i)]\n",
    "                    tag_dict[tag.name + \"_normal_\" + str(len(tmp)-1)] = tmp[len(tmp)-1].get_text()\n",
    "                    text_normal += \"\\n\" + tag_dict[tag.name + \"_normal_\" + str(len(tmp)-1)]\n",
    "                    tag_dict[tag.name + \"_normal\"] = text_normal\n",
    "                if tag.text_embedded is not None:\n",
    "                    tmp = tag.find_all(\"text_embedded\")\n",
    "                    for i in range(len(tmp)-1):\n",
    "                        tag_dict[tag.name + \"_embedded_\" + str(i)] = tmp[i].get_text().replace(tmp[i+1].get_text(),'')\n",
    "                    tag_dict[tag.name + \"_embedded_\" + str(len(tmp)-1)] = tmp[len(tmp)-1].get_text()\n",
    "        df = df.append(pd.DataFrame(tag_dict))\n",
    "    df = df.drop(df.columns[df.notnull().sum() == 0], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AshPKTNiUVCy"
   },
   "outputs": [],
   "source": [
    "df_gen = xml_to_df(\"GenSpam/train_GEN.ems\")\n",
    "df_gen['spam'] = False\n",
    "df_spam = xml_to_df(\"GenSpam/train_SPAM.ems\")\n",
    "df_spam['spam'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jmoAdOxFUVCz"
   },
   "outputs": [],
   "source": [
    "df = df_gen.append(df_spam)\n",
    "df = df.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cptAP-SyUVCz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>message_body_embedded_57</th>\n",
       "      <th>message_body_embedded_58</th>\n",
       "      <th>message_body_embedded_59</th>\n",
       "      <th>message_body_embedded_60</th>\n",
       "      <th>message_body_embedded_61</th>\n",
       "      <th>message_body_embedded_62</th>\n",
       "      <th>message_body_embedded_63</th>\n",
       "      <th>message_body_embedded_64</th>\n",
       "      <th>message_body_embedded_65</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri, 04 Apr 2003 22:00:48 PST</td>\n",
       "      <td>\\n</td>\n",
       "      <td>org</td>\n",
       "      <td>\\n\\n^ Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A House ...</td>\n",
       "      <td>\\n \\n\\n^ Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A Hous...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>\\n\\n^ &amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME A...</td>\n",
       "      <td>\\n \\n\\n^ &amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 26 Mar 03 05:18:06 GMT</td>\n",
       "      <td>com</td>\n",
       "      <td>org</td>\n",
       "      <td>\\n\\n^ Re : online drug store , valium , viagr...</td>\n",
       "      <td>\\n \\n\\n^ Re : online drug store , valium , via...</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri, 2 Jun 2000 13:31:19 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\r\\n\\r\\n^ Re : &amp;NAME ! \\r\\n</td>\n",
       "      <td>\\n \\r\\n\\r\\n^ Re : &amp;NAME ! \\r\\n</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>\\r\\n\\r\\n^ Watch for buses when crossing the r...</td>\n",
       "      <td>\\n \\r\\n\\r\\n^ Watch for buses when crossing the...</td>\n",
       "      <td>\\r\\n\\r\\n^ &amp;NAME ! ! ! ! ! \\r\\n^ It went reall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, 30 Jan 2002 19:49:42 +0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\r\\n\\r\\n^ Re : Information \\r\\n</td>\n",
       "      <td>\\n \\r\\n\\r\\n^ Re : Information \\r\\n</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>\\r\\n\\r\\n^ PS - I like \" &amp;NAME \" ' if it 's al...</td>\n",
       "      <td>\\n \\r\\n\\r\\n^ PS - I like \" &amp;NAME \" ' if it 's ...</td>\n",
       "      <td>\\r\\n\\r\\n^ Dear &amp;NAME , \\r\\n^ &amp;NAME , I forgot...</td>\n",
       "      <td>\\r\\n\\r\\n^ Oh ! ! ! \\r\\n^ Good thing I checked...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, 9 Apr 2003 12:34:43 +0300</td>\n",
       "      <td>\\n</td>\n",
       "      <td>org</td>\n",
       "      <td>\\n\\n^ STOP &amp;NAME STARTING FROM TODAY ( &amp;NAME ...</td>\n",
       "      <td>\\n \\n\\n^ STOP &amp;NAME STARTING FROM TODAY ( &amp;NAM...</td>\n",
       "      <td>text/html; charset=ISO-8859-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     date     from       to  \\\n",
       "0          Fri, 04 Apr 2003 22:00:48 PST        \\n     org    \n",
       "1            Wed, 26 Mar 03 05:18:06 GMT      com      org    \n",
       "2   Fri, 2 Jun 2000 13:31:19 +0100 (BST)    ac.uk    ac.uk    \n",
       "3        Wed, 30 Jan 2002 19:49:42 +0000    ac.uk    ac.uk    \n",
       "4         Wed, 9 Apr 2003 12:34:43 +0300        \\n     org    \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0   \\n\\n^ Q-tips ( &CHAR ) &NAME &NAME : A House ...   \n",
       "1   \\n\\n^ Re : online drug store , valium , viagr...   \n",
       "2                        \\r\\n\\r\\n^ Re : &NAME ! \\r\\n   \n",
       "3                    \\r\\n\\r\\n^ Re : Information \\r\\n   \n",
       "4   \\n\\n^ STOP &NAME STARTING FROM TODAY ( &NAME ...   \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0  \\n \\n\\n^ Q-tips ( &CHAR ) &NAME &NAME : A Hous...   \n",
       "1  \\n \\n\\n^ Re : online drug store , valium , via...   \n",
       "2                     \\n \\r\\n\\r\\n^ Re : &NAME ! \\r\\n   \n",
       "3                 \\n \\r\\n\\r\\n^ Re : Information \\r\\n   \n",
       "4  \\n \\n\\n^ STOP &NAME STARTING FROM TODAY ( &NAM...   \n",
       "\n",
       "                      content-type  \\\n",
       "0   text/html; charset=\"us-ascii\"    \n",
       "1           multipart/alternative    \n",
       "2    TEXT/PLAIN; charset=US-ASCII    \n",
       "3    text/plain; charset=us-ascii    \n",
       "4   text/html; charset=ISO-8859-1    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0   \\n\\n^ &NAME &NAME &NAME - &NAME &NAME &NAME A...   \n",
       "1                                                NaN   \n",
       "2   \\r\\n\\r\\n^ Watch for buses when crossing the r...   \n",
       "3   \\r\\n\\r\\n^ PS - I like \" &NAME \" ' if it 's al...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0  \\n \\n\\n^ &NAME &NAME &NAME - &NAME &NAME &NAME...   \n",
       "1                                                NaN   \n",
       "2  \\n \\r\\n\\r\\n^ Watch for buses when crossing the...   \n",
       "3  \\n \\r\\n\\r\\n^ PS - I like \" &NAME \" ' if it 's ...   \n",
       "4                                                NaN   \n",
       "\n",
       "                             message_body_embedded_0  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2   \\r\\n\\r\\n^ &NAME ! ! ! ! ! \\r\\n^ It went reall...   \n",
       "3   \\r\\n\\r\\n^ Dear &NAME , \\r\\n^ &NAME , I forgot...   \n",
       "4                                                NaN   \n",
       "\n",
       "                             message_body_embedded_1  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1                                                NaN  ...   \n",
       "2                                                NaN  ...   \n",
       "3   \\r\\n\\r\\n^ Oh ! ! ! \\r\\n^ Good thing I checked...  ...   \n",
       "4                                                NaN  ...   \n",
       "\n",
       "  message_body_embedded_57 message_body_embedded_58 message_body_embedded_59  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "  message_body_embedded_60 message_body_embedded_61 message_body_embedded_62  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "  message_body_embedded_63 message_body_embedded_64 message_body_embedded_65  \\\n",
       "0                      NaN                      NaN                      NaN   \n",
       "1                      NaN                      NaN                      NaN   \n",
       "2                      NaN                      NaN                      NaN   \n",
       "3                      NaN                      NaN                      NaN   \n",
       "4                      NaN                      NaN                      NaN   \n",
       "\n",
       "    spam  \n",
       "0   True  \n",
       "1   True  \n",
       "2  False  \n",
       "3  False  \n",
       "4   True  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index().drop(['index'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MXFEHj2qUVC4"
   },
   "outputs": [],
   "source": [
    "filter_col = [col for col in df if col.startswith('message_body') or col.startswith('subject_normal')]\n",
    "for col in filter_col:\n",
    "    df[col] = df[col].apply(lambda x: str(x).replace('\\n','').replace('\\r','').replace('^',''))\n",
    "df['to'] = df['to'].apply(lambda x: str(x).replace('\\n',''))\n",
    "df['from'] = df['from'].apply(lambda x: str(x).replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pre-processed dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvx_QCt8bHvS"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/content/drive/MyDrive/Cambridge/SpamFiltering/df_pre_processing.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eraEekjgDEN",
    "outputId": "858d59c4-c047-494c-ca9a-fba5486f7f11"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_pre_processing.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25oDgSIiUVC6"
   },
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LgYUqRGxUVC8"
   },
   "outputs": [],
   "source": [
    "# number of attributes retained to build models\n",
    "nb_words = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract lemmas for tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y2G9-5MQUVC8"
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def sentence_lemma(x):\n",
    "    try:\n",
    "        word_list = nltk.word_tokenize(x)\n",
    "        lemmatized_output = ' '.join([wordnet_lemmatizer.lemmatize(w) for w in word_list])\n",
    "        return lemmatized_output\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ugjk_txoUVC8"
   },
   "outputs": [],
   "source": [
    "df['subject_body'] = df['subject_normal_0'] + df['message_body_normal_0']\n",
    "df['subject_body'] = df['subject_body'].str.lower()\n",
    "df['subject_body'] = df['subject_body'].apply(lambda x: sentence_lemma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract tokens from subject and body text chunks, compute the information gain of all tokens, and rank tokens according to their information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1pFdh7x9UVC8"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df.loc[df['subject_body'].notna(),'subject_body'])\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tapILFaYUVC9",
    "outputId": "32a7a17a-e524-40fc-b303-a24d5b8cd1d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0719170742000782, 'wrote'),\n",
       " (0.06851656953960494, 'nan'),\n",
       " (0.04473188593734856, 'click'),\n",
       " (0.04434977821089897, 'lick'),\n",
       " (0.04413880021512451, 'clic'),\n",
       " (0.043527897371007984, 'wr'),\n",
       " (0.039914334000032414, ','),\n",
       " (0.039635402286571364, 'hope'),\n",
       " (0.038302958857321656, 'rot'),\n",
       " (0.03604220837976613, 'cli')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_add = True\n",
    "q = []  # priority queue\n",
    "\n",
    "# our tokenization method discards punctuation from the token list\n",
    "# as punctuation distribution differs from genuine and spam messages, we manually add them to the list of tokens to consider\n",
    "punctuation = ['\"',\"'\",\"(\",\")\",\"-\",\"+\",\"[\",\"]\",\"{\",\"}\",\";\",\":\",\",\",\"\\\",\",\"<\",\">\",\".\",\"/\",\"?\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"_\",\"~\"]\n",
    "token_list = vectorizer.get_feature_names() + punctuation\n",
    "\n",
    "text_all = ' '.join(df.loc[df['subject_body'].notna(),'subject_body'])\n",
    "\n",
    "for token in token_list:\n",
    "    to_add = True\n",
    "    # we only consider tokens that appear at least in 4 messages, and that have less than 15 characters\n",
    "    if len(token) > 15 or text_all.count(token) <= 4:\n",
    "        to_add = False\n",
    "        continue\n",
    "    if to_add:\n",
    "        try:\n",
    "            # we add tokens with their information gain to the priority queue\n",
    "            heapq.heappush(q, (info_gain.info_gain(df.spam, df.subject_body.str.contains(token)), token))\n",
    "        except:\n",
    "            continue\n",
    "heapq.nlargest(10, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "700 tokens with best information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_best_ig = ['click',\n",
    " 'lick',\n",
    " 'clic',\n",
    " 'cli',\n",
    " 'lic',\n",
    " 'wrote',\n",
    " 'ick',\n",
    " 'cl',\n",
    " 'bsc',\n",
    " 'subscrib',\n",
    " 'ubscribe',\n",
    " 'subscribe',\n",
    " 'cribe',\n",
    " 'ribe',\n",
    " 'remov',\n",
    " 'scribe',\n",
    " 'unsub',\n",
    " 'scr',\n",
    " 'offer',\n",
    " 'cr',\n",
    " 'unsubs',\n",
    " 'remove',\n",
    " 'emove',\n",
    " 'unsubscr',\n",
    " 'unsubscri',\n",
    " 'unsubscrib',\n",
    " 'nsubscribe',\n",
    " 'unsubscribe',\n",
    " 'unsu',\n",
    " 'cri',\n",
    " 'mov',\n",
    " 'receiv',\n",
    " 'recei',\n",
    " 'free',\n",
    " 'offe',\n",
    " 'ck',\n",
    " 'site',\n",
    " 'move',\n",
    " 'hope',\n",
    " 'wr',\n",
    " 'fre',\n",
    " 'rot',\n",
    " 'receive',\n",
    " 'eceive',\n",
    " 'sub',\n",
    " 'rib',\n",
    " 'web',\n",
    " 'eb',\n",
    " 'ffer',\n",
    " 'bsit',\n",
    " 'website',\n",
    " 'ebsite',\n",
    " 'websi',\n",
    " 'bsi',\n",
    " 'hop',\n",
    " 'your',\n",
    " 'li',\n",
    " 'edi',\n",
    " 'our',\n",
    " 'college',\n",
    " 'rday',\n",
    " 'rec',\n",
    " 'iday',\n",
    " 'think',\n",
    " 'hink',\n",
    " 'rem',\n",
    " 'oved',\n",
    " 'but',\n",
    " 'mailing',\n",
    " 'ub',\n",
    " 'receiving',\n",
    " 'guaran',\n",
    " 'guarantee',\n",
    " 'ite',\n",
    " 'wel',\n",
    " 'ailing',\n",
    " 'oing',\n",
    " 'fer',\n",
    " 'product',\n",
    " 'going',\n",
    " 'goin',\n",
    " 'morrow',\n",
    " 'tomorro',\n",
    " 'tomorrow',\n",
    " 'orrow',\n",
    " 'mark',\n",
    " 'sit',\n",
    " 'good',\n",
    " 'valu',\n",
    " 'cre',\n",
    " 'well',\n",
    " 'evenin',\n",
    " 'sc',\n",
    " 'universit',\n",
    " 'evening',\n",
    " 'university',\n",
    " 'off',\n",
    " 'emoved',\n",
    " 'my',\n",
    " 'goo',\n",
    " 'sorry',\n",
    " 'duct',\n",
    " 'low',\n",
    " 'prod',\n",
    " 'love',\n",
    " 'lin',\n",
    " 'lov',\n",
    " 'ov',\n",
    " 'thanks',\n",
    " 'anyway',\n",
    " 'affiliate',\n",
    " 'iz',\n",
    " 'know',\n",
    " 'kno',\n",
    " 'sav',\n",
    " 'coll',\n",
    " 'here',\n",
    " 'ib',\n",
    " 'opt',\n",
    " 'online',\n",
    " 'va',\n",
    " 'nive',\n",
    " 'onli',\n",
    " 'onlin',\n",
    " 'stud',\n",
    " 'ei',\n",
    " 'removed',\n",
    " 'oon',\n",
    " 'credi',\n",
    " 'rod',\n",
    " 'moved',\n",
    " 'ote',\n",
    " 'ved',\n",
    " 'nl',\n",
    " 'quite',\n",
    " 'dear',\n",
    " 'fe',\n",
    " 'fr',\n",
    " 'thank',\n",
    " 'rant',\n",
    " 'mo',\n",
    " 'ze',\n",
    " 'though',\n",
    " 'oin',\n",
    " 'link',\n",
    " 'christ',\n",
    " 'saturday',\n",
    " 'prove',\n",
    " 'edit',\n",
    " 'sd',\n",
    " 'tues',\n",
    " 'tuesday',\n",
    " 'some',\n",
    " 'nda',\n",
    " 'thin',\n",
    " 'sex',\n",
    " 'som',\n",
    " 'friday',\n",
    " 'orry',\n",
    " 'guaranteed',\n",
    " 'riday',\n",
    " 'ic',\n",
    " 'shipp',\n",
    " 'below',\n",
    " 'ante',\n",
    " 'credit',\n",
    " 'rda',\n",
    " 'monday',\n",
    " 'onday',\n",
    " 'dit',\n",
    " 'save',\n",
    " 'go',\n",
    " 'acy',\n",
    " 'lua',\n",
    " 'list',\n",
    " 'student',\n",
    " 'iv',\n",
    " 'riber',\n",
    " 'dollar',\n",
    " 'medic',\n",
    " 'subscriber',\n",
    " 'meeting',\n",
    " 'usine',\n",
    " 'busines',\n",
    " 'usiness',\n",
    " 'business',\n",
    " 'siness',\n",
    " 'cial',\n",
    " 'there',\n",
    " 'thur',\n",
    " 'partner',\n",
    " 'request',\n",
    " 'market',\n",
    " 'servic',\n",
    " 'thurs',\n",
    " 'ff',\n",
    " 'service',\n",
    " 'servi',\n",
    " 'weekend',\n",
    " 'rida',\n",
    " 'opted',\n",
    " 'pray',\n",
    " 'sunday',\n",
    " 'week',\n",
    " 'pra',\n",
    " 'special',\n",
    " 'pecial',\n",
    " 'privacy',\n",
    " 'si',\n",
    " 'doll',\n",
    " 'hin',\n",
    " 'req',\n",
    " 'ur',\n",
    " 'incr',\n",
    " 'future',\n",
    " 'futur',\n",
    " 'yesterday',\n",
    " 'altho',\n",
    " 'money',\n",
    " 'ive',\n",
    " 'thursday',\n",
    " 'tue',\n",
    " 'limi',\n",
    " 'ncr',\n",
    " 'serv',\n",
    " 'holiday',\n",
    " 'wee',\n",
    " 'althoug',\n",
    " 'fut',\n",
    " 'although',\n",
    " 'oney',\n",
    " 'shipping',\n",
    " 'valuable',\n",
    " 'day',\n",
    " 'morn',\n",
    " 'lecture',\n",
    " 'bel',\n",
    " 'limited',\n",
    " 'million',\n",
    " 'millio',\n",
    " 'mited',\n",
    " 'ere',\n",
    " 'rtn',\n",
    " 'limite',\n",
    " 'morning',\n",
    " 'lion',\n",
    " 'noon',\n",
    " 'name',\n",
    " 'red',\n",
    " 'fast',\n",
    " 'xu',\n",
    " 'hri',\n",
    " 'rtg',\n",
    " 'soo',\n",
    " 'ser',\n",
    " 'marketing',\n",
    " 'lowest',\n",
    " 'noo',\n",
    " 'did',\n",
    " 'so',\n",
    " 'chee',\n",
    " 'siz',\n",
    " 'soon',\n",
    " 'pt',\n",
    " 'which',\n",
    " 'smiley',\n",
    " 'ley',\n",
    " 'hich',\n",
    " 'seem',\n",
    " 'mortgage',\n",
    " ':',\n",
    " 'thu',\n",
    " 'mill',\n",
    " 'owes',\n",
    " 'hopeful',\n",
    " 'tn',\n",
    " 'ipp',\n",
    " 'increase',\n",
    " 'limit',\n",
    " 'hall',\n",
    " 'mg',\n",
    " 'sol',\n",
    " 'hav',\n",
    " 'ot',\n",
    " 'am',\n",
    " 'hopefully',\n",
    " 'rwa',\n",
    " 'ney',\n",
    " 'had',\n",
    " 'this',\n",
    " 'lio',\n",
    " 'ia',\n",
    " 'smile',\n",
    " 'afternoon',\n",
    " 'dol',\n",
    " 'inc',\n",
    " 'approved',\n",
    " 'cheer',\n",
    " 'hat',\n",
    " 'pay',\n",
    " 'prayer',\n",
    " 'simply',\n",
    " 'christmas',\n",
    " 'tha',\n",
    " 'proved',\n",
    " 'eek',\n",
    " 'ara',\n",
    " 'uld',\n",
    " 'lot',\n",
    " 'vice',\n",
    " 'imply',\n",
    " 'after',\n",
    " 'fter',\n",
    " 'wednesday',\n",
    " 'exual',\n",
    " 'have',\n",
    " 'sexual',\n",
    " 'approve',\n",
    " 'ning',\n",
    " 'age',\n",
    " 'cia',\n",
    " 'quit',\n",
    " 'thing',\n",
    " 'upply',\n",
    " 'west',\n",
    " 'lu',\n",
    " 'meet',\n",
    " 'oval',\n",
    " 'priv',\n",
    " 'postal',\n",
    " 'supply',\n",
    " 'speak',\n",
    " 'aft',\n",
    " 'asy',\n",
    " 'talk',\n",
    " 'ther',\n",
    " 'line',\n",
    " 'him',\n",
    " 'ray',\n",
    " 'eq',\n",
    " 'ip',\n",
    " 'ec',\n",
    " 'du',\n",
    " 'ym',\n",
    " 'ably',\n",
    " 'ship',\n",
    " 'tee',\n",
    " 'gt',\n",
    " 'lovely',\n",
    " 'thousand',\n",
    " 'ial',\n",
    " ',',\n",
    " 'na',\n",
    " 'erc',\n",
    " 'doctor',\n",
    " 'gua',\n",
    " 'organis',\n",
    " 'next',\n",
    " 'sun',\n",
    " 'octor',\n",
    " 'lunch',\n",
    " 'dinner',\n",
    " 'shoul',\n",
    " 'qual',\n",
    " 'probabl',\n",
    " 'purchase',\n",
    " 'mile',\n",
    " 'should',\n",
    " 'her',\n",
    " 'his',\n",
    " 'spec',\n",
    " 'bc',\n",
    " 'rv',\n",
    " 'probably',\n",
    " 'nin',\n",
    " 'ni',\n",
    " 'forward',\n",
    " 'month',\n",
    " 'nice',\n",
    " 'might',\n",
    " 'tg',\n",
    " 'perhaps',\n",
    " 'onth',\n",
    " 'iva',\n",
    " 'went',\n",
    " 'room',\n",
    " 'ce',\n",
    " 'sim',\n",
    " 'hip',\n",
    " 'size',\n",
    " 'fte',\n",
    " 'color',\n",
    " 'oo',\n",
    " 'aff',\n",
    " 'church',\n",
    " 'duat',\n",
    " 'col',\n",
    " 'ken',\n",
    " 'hey',\n",
    " 'wed',\n",
    " 'easy',\n",
    " '00',\n",
    " 'ase',\n",
    " 'marked',\n",
    " 'href',\n",
    " 'agin',\n",
    " 'vac',\n",
    " 'ply',\n",
    " 'posta',\n",
    " 'ua',\n",
    " 'say',\n",
    " 'trade',\n",
    " 'chase',\n",
    " 'lender',\n",
    " 'custo',\n",
    " 'rom',\n",
    " 'yet',\n",
    " 'graduate',\n",
    " 'customer',\n",
    " 'removal',\n",
    " 'oup',\n",
    " 'su',\n",
    " 'ail',\n",
    " 'pg',\n",
    " 'movie',\n",
    " 'peak',\n",
    " 'hee',\n",
    " 'dv',\n",
    " 'custom',\n",
    " 'vi',\n",
    " 'solicit',\n",
    " 'value',\n",
    " 'cust',\n",
    " 'suppl',\n",
    " 'yy',\n",
    " 'uality',\n",
    " 'that',\n",
    " 'birthday',\n",
    " 'saving',\n",
    " 'sf',\n",
    " 'oi',\n",
    " 'trademark',\n",
    " 'qualit',\n",
    " 'rather',\n",
    " 'arg',\n",
    " 'rma',\n",
    " 'quality',\n",
    " 'scription',\n",
    " 'price',\n",
    " 'rade',\n",
    " 'chas',\n",
    " 'over',\n",
    " 'pro',\n",
    " 'retail',\n",
    " 'nex',\n",
    " 'linguist',\n",
    " 'high',\n",
    " 'hig',\n",
    " 'safe',\n",
    " 'ay',\n",
    " 'hundred',\n",
    " 'rid',\n",
    " 'reall',\n",
    " 'usa',\n",
    " 'really',\n",
    " 'hing',\n",
    " 'ag',\n",
    " 'more',\n",
    " 'dieti',\n",
    " 'eight',\n",
    " 'faster',\n",
    " 'dieting',\n",
    " 'ger',\n",
    " 'finish',\n",
    " 'finis',\n",
    " 'from',\n",
    " 'bout',\n",
    " 'eas',\n",
    " 'net',\n",
    " 'hear',\n",
    " 'study',\n",
    " 'nte',\n",
    " 'rice',\n",
    " 'about',\n",
    " 'bz',\n",
    " 'yme',\n",
    " 'zp',\n",
    " 'ease',\n",
    " 'linguistic',\n",
    " 'pri',\n",
    " 'till',\n",
    " 'hg',\n",
    " 'mat',\n",
    " 'sometime',\n",
    " 'reserved',\n",
    " 'video',\n",
    " 'yon',\n",
    " 'unsol',\n",
    " 'solicite',\n",
    " 'subscribed',\n",
    " 'bscribed',\n",
    " 'seein',\n",
    " 'ici',\n",
    " 'solicited',\n",
    " 'sound',\n",
    " 'seeing',\n",
    " 'unsolicited',\n",
    " 'weight',\n",
    " 'urself',\n",
    " 'seems',\n",
    " 'gues',\n",
    " 'redu',\n",
    " 'sand',\n",
    " 'ourself',\n",
    " 'fro',\n",
    " 'language',\n",
    " 'nger',\n",
    " 'zi',\n",
    " 'gag',\n",
    " 'gage',\n",
    " 'mp',\n",
    " 'got',\n",
    " 'yourself',\n",
    " 'me',\n",
    " 'guess',\n",
    " 'flat',\n",
    " 'athe',\n",
    " 'obligation',\n",
    " '30pm',\n",
    " 'langu',\n",
    " 'payment',\n",
    " 'ant',\n",
    " 'uess',\n",
    " 'fit',\n",
    " 'nso',\n",
    " 'then',\n",
    " 'earn',\n",
    " 'rever',\n",
    " 'fwd',\n",
    " 'ideo',\n",
    " 'umm',\n",
    " '100',\n",
    " 'people',\n",
    " 'motion',\n",
    " 'she',\n",
    " 'edici',\n",
    " 'dicine',\n",
    " 'they',\n",
    " 'edicine',\n",
    " 'uage',\n",
    " 'deo',\n",
    " 'medicine',\n",
    " 'emark',\n",
    " 'emar',\n",
    " 'exclusive',\n",
    " 'loan',\n",
    " 'kt',\n",
    " 'message',\n",
    " 'vid',\n",
    " 'messag',\n",
    " 'doc',\n",
    " '30p',\n",
    " 'revers',\n",
    " 'formal',\n",
    " 'ture',\n",
    " 'instruction',\n",
    " 'ont',\n",
    " 'nth',\n",
    " 'weigh',\n",
    " 'also',\n",
    " 'informatio',\n",
    " 'information',\n",
    " 'lend',\n",
    " 'nformation',\n",
    " 'ness',\n",
    " 'muscle',\n",
    " 'avenue',\n",
    " 'reserve',\n",
    " 'income',\n",
    " 'erect',\n",
    " 'tv',\n",
    " 'ek',\n",
    " 'discreet',\n",
    " 'hl',\n",
    " 'enter',\n",
    " 'see',\n",
    " 'yd',\n",
    " 'ality',\n",
    " 'hda',\n",
    " 'instruct',\n",
    " 'qr',\n",
    " 'proven',\n",
    " 'gation',\n",
    " 'exclu',\n",
    " 'christian',\n",
    " 'wish',\n",
    " 'instruc',\n",
    " 'sage',\n",
    " 'isf',\n",
    " 'informat',\n",
    " 'ende',\n",
    " 'would',\n",
    " 'formation',\n",
    " 'ello',\n",
    " 'guy',\n",
    " 'yz',\n",
    " 'through',\n",
    " 'dad',\n",
    " 'meal',\n",
    " 'fb',\n",
    " 'imp',\n",
    " 'improve',\n",
    " 'throug',\n",
    " 'improv',\n",
    " 'ich',\n",
    " 'rmation',\n",
    " 'liga',\n",
    " 'git',\n",
    " 'nigh',\n",
    " 'mar',\n",
    " 'far',\n",
    " 'ngt',\n",
    " 'hic',\n",
    " 'pill',\n",
    " 'night',\n",
    " 'course',\n",
    " 'informa',\n",
    " 'investment',\n",
    " 'cur',\n",
    " 'ques',\n",
    " 'instru',\n",
    " 'nlarge',\n",
    " 'enlarge',\n",
    " 'ling',\n",
    " 'deliver',\n",
    " 'mati',\n",
    " '%',\n",
    " 'ear',\n",
    " 'scribed',\n",
    " 'risk',\n",
    " 'geo',\n",
    " 'okay',\n",
    " 'nlar',\n",
    " 'sag',\n",
    " 'bh',\n",
    " 'linguistics',\n",
    " 'mation',\n",
    " 'uc',\n",
    " 'satis',\n",
    " 'instant',\n",
    " 'recurring',\n",
    " 'enlarg',\n",
    " 'enlar',\n",
    " 'lud',\n",
    " 'prof',\n",
    " 'wonder',\n",
    " 'prob',\n",
    " 'tio',\n",
    " 'subscription',\n",
    " 'uite',\n",
    " 'clud',\n",
    " 'practical',\n",
    " 'quest',\n",
    " 'tion',\n",
    " 'liver',\n",
    " 'exerci',\n",
    " 'resting',\n",
    " 'fri',\n",
    " 'fini',\n",
    " 'med',\n",
    " '34',\n",
    " 'busy',\n",
    " 'interesti',\n",
    " 'icin',\n",
    " 'ave',\n",
    " 'vie',\n",
    " 'stuff',\n",
    " 'hello',\n",
    " 'usc',\n",
    " 'disco',\n",
    " 'interestin',\n",
    " 'coul',\n",
    " 'sletter',\n",
    " 'afe',\n",
    " 'gi',\n",
    " 'reduce',\n",
    " 'interesting',\n",
    " 'could',\n",
    " 'consumer',\n",
    " 'rough',\n",
    " 'rof',\n",
    " 'thro',\n",
    " 'medical',\n",
    " 'exercise',\n",
    " 'thr',\n",
    " 'ran',\n",
    " 'agra',\n",
    " 'diet',\n",
    " 'usi',\n",
    " 'iu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the tokens retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIctBwkiUVC9",
    "outputId": "4a122adb-f621-4adb-df6f-de7ab03bf93c"
   },
   "outputs": [],
   "source": [
    "vocab_best_ig = pd.DataFrame(heapq.nlargest(nb_words,q))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_tf = [col + '_tf' for col in vocab_best_ig]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe with Term-Frequency attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of occurrences of the tokens retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tf</th>\n",
       "      <th>valuable_tf</th>\n",
       "      <th>invit_tf</th>\n",
       "      <th>committee_tf</th>\n",
       "      <th>tin_tf</th>\n",
       "      <th>work_tf</th>\n",
       "      <th>sci_tf</th>\n",
       "      <th>cult_tf</th>\n",
       "      <th>link_tf</th>\n",
       "      <th>7th_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri, 04 Apr 2003 22:00:48 PST</td>\n",
       "      <td></td>\n",
       "      <td>org</td>\n",
       "      <td>Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A House Full ...</td>\n",
       "      <td>Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A House Full ...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>&amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME April ...</td>\n",
       "      <td>&amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME April ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 26 Mar 03 05:18:06 GMT</td>\n",
       "      <td>com</td>\n",
       "      <td>org</td>\n",
       "      <td>Re : online drug store , valium , viagra , z...</td>\n",
       "      <td>Re : online drug store , valium , viagra , z...</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri, 2 Jun 2000 13:31:19 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>Re : &amp;NAME !</td>\n",
       "      <td>Re : &amp;NAME !</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>Watch for buses when crossing the road .  In...</td>\n",
       "      <td>Watch for buses when crossing the road .  In...</td>\n",
       "      <td>&amp;NAME ! ! ! ! !  It went really well ( compa...</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, 30 Jan 2002 19:49:42 +0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>Re : Information</td>\n",
       "      <td>Re : Information</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>PS - I like \" &amp;NAME \" ' if it 's all the sam...</td>\n",
       "      <td>PS - I like \" &amp;NAME \" ' if it 's all the sam...</td>\n",
       "      <td>Dear &amp;NAME ,  &amp;NAME , I forgot to mention to...</td>\n",
       "      <td>Oh ! ! !  Good thing I checked my email just...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, 9 Apr 2003 12:34:43 +0300</td>\n",
       "      <td></td>\n",
       "      <td>org</td>\n",
       "      <td>STOP &amp;NAME STARTING FROM TODAY ( &amp;NAME : &amp;NA...</td>\n",
       "      <td>STOP &amp;NAME STARTING FROM TODAY ( &amp;NAME : &amp;NA...</td>\n",
       "      <td>text/html; charset=ISO-8859-1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     date     from       to  \\\n",
       "0          Fri, 04 Apr 2003 22:00:48 PST               org    \n",
       "1            Wed, 26 Mar 03 05:18:06 GMT      com      org    \n",
       "2   Fri, 2 Jun 2000 13:31:19 +0100 (BST)    ac.uk    ac.uk    \n",
       "3        Wed, 30 Jan 2002 19:49:42 +0000    ac.uk    ac.uk    \n",
       "4         Wed, 9 Apr 2003 12:34:43 +0300               org    \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0    Q-tips ( &CHAR ) &NAME &NAME : A House Full ...   \n",
       "1    Re : online drug store , valium , viagra , z...   \n",
       "2                                      Re : &NAME !    \n",
       "3                                  Re : Information    \n",
       "4    STOP &NAME STARTING FROM TODAY ( &NAME : &NA...   \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0    Q-tips ( &CHAR ) &NAME &NAME : A House Full ...   \n",
       "1    Re : online drug store , valium , viagra , z...   \n",
       "2                                      Re : &NAME !    \n",
       "3                                  Re : Information    \n",
       "4    STOP &NAME STARTING FROM TODAY ( &NAME : &NA...   \n",
       "\n",
       "                      content-type  \\\n",
       "0   text/html; charset=\"us-ascii\"    \n",
       "1           multipart/alternative    \n",
       "2    TEXT/PLAIN; charset=US-ASCII    \n",
       "3    text/plain; charset=us-ascii    \n",
       "4   text/html; charset=ISO-8859-1    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    &NAME &NAME &NAME - &NAME &NAME &NAME April ...   \n",
       "1                                                nan   \n",
       "2    Watch for buses when crossing the road .  In...   \n",
       "3    PS - I like \" &NAME \" ' if it 's all the sam...   \n",
       "4                                                nan   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0    &NAME &NAME &NAME - &NAME &NAME &NAME April ...   \n",
       "1                                                nan   \n",
       "2    Watch for buses when crossing the road .  In...   \n",
       "3    PS - I like \" &NAME \" ' if it 's all the sam...   \n",
       "4                                                nan   \n",
       "\n",
       "                             message_body_embedded_0  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2    &NAME ! ! ! ! !  It went really well ( compa...   \n",
       "3    Dear &NAME ,  &NAME , I forgot to mention to...   \n",
       "4                                                nan   \n",
       "\n",
       "                             message_body_embedded_1  ... mean_tf valuable_tf  \\\n",
       "0                                                nan  ...       0           0   \n",
       "1                                                nan  ...       0           0   \n",
       "2                                                nan  ...       0           0   \n",
       "3    Oh ! ! !  Good thing I checked my email just...  ...       0           0   \n",
       "4                                                nan  ...       0           0   \n",
       "\n",
       "  invit_tf committee_tf tin_tf work_tf sci_tf cult_tf link_tf 7th_tf  \n",
       "0        0            0      2       0      0       0       1      0  \n",
       "1        0            0      0       0      0       0       0      0  \n",
       "2        0            0      0       0      1       0       0      0  \n",
       "3        0            0      0       0      0       0       0      0  \n",
       "4        0            0      1       0      0       0       0      0  \n",
       "\n",
       "[5 rows x 798 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf = df.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_tf[token + '_tf'] = df_tf.subject_body.str.count(token)\n",
    "df_tf[col_names_tf] = df_tf[col_names_tf].fillna(0)\n",
    "df_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stored best tokens count in a dataframe for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_train = df_tf[list(col_names_tf) + ['spam']].dropna()\n",
    "df_tf_train = df_tf_train.astype(int)\n",
    "df_tf_train.to_csv(\"data_tf/data_\" + str(nb_words) + \".train\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe with Boolean attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean attributes indicating if a given message contains a given token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "TYAzZn-mUVC9",
    "outputId": "fe901de2-2c27-40d2-c110-d3c236aa2e3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>valuable</th>\n",
       "      <th>invit</th>\n",
       "      <th>committee</th>\n",
       "      <th>tin</th>\n",
       "      <th>work</th>\n",
       "      <th>sci</th>\n",
       "      <th>cult</th>\n",
       "      <th>link</th>\n",
       "      <th>7th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri, 04 Apr 2003 22:00:48 PST</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A House Full ...</td>\n",
       "      <td>Q-tips ( &amp;CHAR ) &amp;NAME &amp;NAME : A House Full ...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>&amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME April ...</td>\n",
       "      <td>&amp;NAME &amp;NAME &amp;NAME - &amp;NAME &amp;NAME &amp;NAME April ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed, 26 Mar 03 05:18:06 GMT</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>Re : online drug store , valium , viagra , z...</td>\n",
       "      <td>Re : online drug store , valium , viagra , z...</td>\n",
       "      <td>multipart/alternative</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri, 2 Jun 2000 13:31:19 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>False</td>\n",
       "      <td>Re : &amp;NAME !</td>\n",
       "      <td>Re : &amp;NAME !</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>Watch for buses when crossing the road .  In...</td>\n",
       "      <td>Watch for buses when crossing the road .  In...</td>\n",
       "      <td>&amp;NAME ! ! ! ! !  It went really well ( compa...</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed, 30 Jan 2002 19:49:42 +0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>True</td>\n",
       "      <td>Re : Information</td>\n",
       "      <td>Re : Information</td>\n",
       "      <td>text/plain; charset=us-ascii</td>\n",
       "      <td>PS - I like \" &amp;NAME \" ' if it 's all the sam...</td>\n",
       "      <td>PS - I like \" &amp;NAME \" ' if it 's all the sam...</td>\n",
       "      <td>Dear &amp;NAME ,  &amp;NAME , I forgot to mention to...</td>\n",
       "      <td>Oh ! ! !  Good thing I checked my email just...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, 9 Apr 2003 12:34:43 +0300</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>STOP &amp;NAME STARTING FROM TODAY ( &amp;NAME : &amp;NA...</td>\n",
       "      <td>STOP &amp;NAME STARTING FROM TODAY ( &amp;NAME : &amp;NA...</td>\n",
       "      <td>text/html; charset=ISO-8859-1</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     date     from     to  \\\n",
       "0          Fri, 04 Apr 2003 22:00:48 PST             True   \n",
       "1            Wed, 26 Mar 03 05:18:06 GMT      com    True   \n",
       "2   Fri, 2 Jun 2000 13:31:19 +0100 (BST)    ac.uk   False   \n",
       "3        Wed, 30 Jan 2002 19:49:42 +0000    ac.uk    True   \n",
       "4         Wed, 9 Apr 2003 12:34:43 +0300             True   \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0    Q-tips ( &CHAR ) &NAME &NAME : A House Full ...   \n",
       "1    Re : online drug store , valium , viagra , z...   \n",
       "2                                      Re : &NAME !    \n",
       "3                                  Re : Information    \n",
       "4    STOP &NAME STARTING FROM TODAY ( &NAME : &NA...   \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0    Q-tips ( &CHAR ) &NAME &NAME : A House Full ...   \n",
       "1    Re : online drug store , valium , viagra , z...   \n",
       "2                                      Re : &NAME !    \n",
       "3                                  Re : Information    \n",
       "4    STOP &NAME STARTING FROM TODAY ( &NAME : &NA...   \n",
       "\n",
       "                      content-type  \\\n",
       "0   text/html; charset=\"us-ascii\"    \n",
       "1           multipart/alternative    \n",
       "2    TEXT/PLAIN; charset=US-ASCII    \n",
       "3    text/plain; charset=us-ascii    \n",
       "4   text/html; charset=ISO-8859-1    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    &NAME &NAME &NAME - &NAME &NAME &NAME April ...   \n",
       "1                                                nan   \n",
       "2    Watch for buses when crossing the road .  In...   \n",
       "3    PS - I like \" &NAME \" ' if it 's all the sam...   \n",
       "4                                                nan   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0    &NAME &NAME &NAME - &NAME &NAME &NAME April ...   \n",
       "1                                                nan   \n",
       "2    Watch for buses when crossing the road .  In...   \n",
       "3    PS - I like \" &NAME \" ' if it 's all the sam...   \n",
       "4                                                nan   \n",
       "\n",
       "                             message_body_embedded_0  \\\n",
       "0                                                nan   \n",
       "1                                                nan   \n",
       "2    &NAME ! ! ! ! !  It went really well ( compa...   \n",
       "3    Dear &NAME ,  &NAME , I forgot to mention to...   \n",
       "4                                                nan   \n",
       "\n",
       "                             message_body_embedded_1  ...   mean valuable  \\\n",
       "0                                                nan  ...  False    False   \n",
       "1                                                nan  ...  False    False   \n",
       "2                                                nan  ...  False    False   \n",
       "3    Oh ! ! !  Good thing I checked my email just...  ...  False    False   \n",
       "4                                                nan  ...  False    False   \n",
       "\n",
       "   invit committee    tin   work    sci   cult   link    7th  \n",
       "0  False     False   True  False  False  False   True  False  \n",
       "1  False     False  False  False  False  False  False  False  \n",
       "2  False     False  False  False   True  False  False  False  \n",
       "3  False     False  False  False  False  False  False  False  \n",
       "4  False     False   True  False  False  False  False  False  \n",
       "\n",
       "[5 rows x 797 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timbl = df.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_timbl[token] = df_timbl.subject_body.str.contains(token)\n",
    "df_timbl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stored best boolean attributes in a dataframe for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "OJdwAfy7UVC9"
   },
   "outputs": [],
   "source": [
    "df_timbl_train = df_timbl[list(vocab_best_ig) + ['spam']].dropna()\n",
    "df_timbl_train = df_timbl_train.astype(int)\n",
    "df_timbl_train.to_csv(\"data_timbl/data_\" + str(nb_words) + \".train\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTZF4Gw6UVC_"
   },
   "source": [
    "## Adaptation set pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and extract data from the adaptation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PamDsu76UVC_"
   },
   "outputs": [],
   "source": [
    "df_gen_adap = xml_to_df(\"GenSpam/adapt_GEN.ems\")\n",
    "df_gen_adap['spam'] = False\n",
    "df_spam_adap = xml_to_df(\"GenSpam/adapt_SPAM.ems\")\n",
    "df_spam_adap['spam'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ycoryZQcUVC_"
   },
   "outputs": [],
   "source": [
    "df_adap = df_gen_adap.append(df_spam_adap)\n",
    "df_adap = df_adap.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "f2PQQDwLUVDA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>message_body_embedded_5</th>\n",
       "      <th>message_body_embedded_6</th>\n",
       "      <th>message_body_normal_4</th>\n",
       "      <th>message_body_normal_5</th>\n",
       "      <th>message_body_normal_6</th>\n",
       "      <th>message_body_normal_7</th>\n",
       "      <th>message_body_normal_8</th>\n",
       "      <th>message_body_embedded_7</th>\n",
       "      <th>spam</th>\n",
       "      <th>message_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Sep 2002 13:24:26 -1700</td>\n",
       "      <td>net</td>\n",
       "      <td>edu</td>\n",
       "      <td>\\n\\n^ &amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME \\n</td>\n",
       "      <td>\\n \\n\\n^ &amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME \\n</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>\\n\\n^ SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME : &amp;...</td>\n",
       "      <td>\\n \\n\\n^ SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME :...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, 25 Mar 2003 02:19:55 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ ... Lock in on low rates - &amp;NAME &amp;NUM -...</td>\n",
       "      <td>\\n \\n\\n^ ... Lock in on low rates - &amp;NAME &amp;NUM...</td>\n",
       "      <td>text/html;</td>\n",
       "      <td>\\n\\n^ &amp;NAME If you wish to unsubscribe from &amp;...</td>\n",
       "      <td>\\n \\n\\n^ &amp;NAME If you wish to unsubscribe from...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 4 Dec 2002 17:14:13 -0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ &amp;NAME applications \\n</td>\n",
       "      <td>\\n \\n\\n^ &amp;NAME applications \\n</td>\n",
       "      <td>text/plain; charset=\"us-ascii\"</td>\n",
       "      <td>\\n\\n^ The Lab 's Industrial Supporters ' &amp;NAM...</td>\n",
       "      <td>\\n \\n\\n^ The Lab 's Industrial Supporters ' &amp;N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri, 22 Nov 2002 09:44:23 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ COPY ANY &amp;NAME TO A &amp;NAME \\n</td>\n",
       "      <td>\\n \\n\\n^ COPY ANY &amp;NAME TO A &amp;NAME \\n</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>\\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &amp;NAM...</td>\n",
       "      <td>\\n \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &amp;N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon, 3 Feb 2003 21:22:25 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>\\n</td>\n",
       "      <td>\\n\\n^ NEW / / COPY ANY &amp;NAME TO &amp;NAME \\n</td>\n",
       "      <td>\\n \\n\\n^ NEW / / COPY ANY &amp;NAME TO &amp;NAME \\n</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>\\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &amp;NAM...</td>\n",
       "      <td>\\n \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &amp;N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date     from       to  \\\n",
       "0   Tue, 10 Sep 2002 13:24:26 -1700      net      edu    \n",
       "1   Tue, 25 Mar 2003 02:19:55 -0800      com    ac.uk    \n",
       "2    Wed, 4 Dec 2002 17:14:13 -0000    ac.uk    ac.uk    \n",
       "3   Fri, 22 Nov 2002 09:44:23 -0800      com    ac.uk    \n",
       "4    Mon, 3 Feb 2003 21:22:25 -0800      com        \\n   \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0       \\n\\n^ &NAME &NAME Watch , ' &NAME ' &NAME \\n   \n",
       "1   \\n\\n^ ... Lock in on low rates - &NAME &NUM -...   \n",
       "2                        \\n\\n^ &NAME applications \\n   \n",
       "3                 \\n\\n^ COPY ANY &NAME TO A &NAME \\n   \n",
       "4           \\n\\n^ NEW / / COPY ANY &NAME TO &NAME \\n   \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0    \\n \\n\\n^ &NAME &NAME Watch , ' &NAME ' &NAME \\n   \n",
       "1  \\n \\n\\n^ ... Lock in on low rates - &NAME &NUM...   \n",
       "2                     \\n \\n\\n^ &NAME applications \\n   \n",
       "3              \\n \\n\\n^ COPY ANY &NAME TO A &NAME \\n   \n",
       "4        \\n \\n\\n^ NEW / / COPY ANY &NAME TO &NAME \\n   \n",
       "\n",
       "                         content-type  \\\n",
       "0    text/html; charset=\"iso-8859-1\"    \n",
       "1                         text/html;    \n",
       "2     text/plain; charset=\"us-ascii\"    \n",
       "3   text/plain; charset=\"iso-8859-1\"    \n",
       "4   text/plain; charset=\"iso-8859-1\"    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0   \\n\\n^ SPECIAL ALERT The &NAME &NAME &NAME : &...   \n",
       "1   \\n\\n^ &NAME If you wish to unsubscribe from &...   \n",
       "2   \\n\\n^ The Lab 's Industrial Supporters ' &NAM...   \n",
       "3   \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &NAM...   \n",
       "4   \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &NAM...   \n",
       "\n",
       "                                 message_body_normal message_body_embedded_0  \\\n",
       "0  \\n \\n\\n^ SPECIAL ALERT The &NAME &NAME &NAME :...                     NaN   \n",
       "1  \\n \\n\\n^ &NAME If you wish to unsubscribe from...                     NaN   \n",
       "2  \\n \\n\\n^ The Lab 's Industrial Supporters ' &N...                     NaN   \n",
       "3  \\n \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &N...                     NaN   \n",
       "4  \\n \\n\\n^ UNSUBSCRIBE AT THE BOTTOM \\n^ Dear &N...                     NaN   \n",
       "\n",
       "  message_body_embedded_1  ... message_body_embedded_5  \\\n",
       "0                     NaN  ...                     NaN   \n",
       "1                     NaN  ...                     NaN   \n",
       "2                     NaN  ...                     NaN   \n",
       "3                     NaN  ...                     NaN   \n",
       "4                     NaN  ...                     NaN   \n",
       "\n",
       "  message_body_embedded_6 message_body_normal_4 message_body_normal_5  \\\n",
       "0                     NaN                   NaN                   NaN   \n",
       "1                     NaN                   NaN                   NaN   \n",
       "2                     NaN                   NaN                   NaN   \n",
       "3                     NaN                   NaN                   NaN   \n",
       "4                     NaN                   NaN                   NaN   \n",
       "\n",
       "  message_body_normal_6 message_body_normal_7 message_body_normal_8  \\\n",
       "0                   NaN                   NaN                   NaN   \n",
       "1                   NaN                   NaN                   NaN   \n",
       "2                   NaN                   NaN                   NaN   \n",
       "3                   NaN                   NaN                   NaN   \n",
       "4                   NaN                   NaN                   NaN   \n",
       "\n",
       "  message_body_embedded_7   spam message_body  \n",
       "0                     NaN   True          NaN  \n",
       "1                     NaN   True          NaN  \n",
       "2                     NaN  False          NaN  \n",
       "3                     NaN   True          NaN  \n",
       "4                     NaN   True          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adap = df_adap.reset_index().drop(['index'], axis=1)\n",
    "df_adap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "N1zoPMk-UVDA"
   },
   "outputs": [],
   "source": [
    "filter_col = [col for col in df_adap if col.startswith('message_body') or col.startswith('subject_normal')]\n",
    "for col in filter_col:\n",
    "    df_adap[col] = df_adap[col].apply(lambda x: str(x).replace('\\n','').replace('\\r','').replace('^',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QYVa2RYqUVDA"
   },
   "outputs": [],
   "source": [
    "df_adap['subject_body'] = df_adap['subject_normal_0'] + df_adap['message_body_normal_0']\n",
    "df_adap['subject_body'] = df_adap['subject_body'].str.lower()\n",
    "df_adap['subject_body'] = df_adap['subject_body'].apply(lambda x: sentence_lemma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract Term-Frequency attributes for the best tokens retained and save the corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tf</th>\n",
       "      <th>valuable_tf</th>\n",
       "      <th>invit_tf</th>\n",
       "      <th>committee_tf</th>\n",
       "      <th>tin_tf</th>\n",
       "      <th>work_tf</th>\n",
       "      <th>sci_tf</th>\n",
       "      <th>cult_tf</th>\n",
       "      <th>link_tf</th>\n",
       "      <th>7th_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Sep 2002 13:24:26 -1700</td>\n",
       "      <td>net</td>\n",
       "      <td>edu</td>\n",
       "      <td>&amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME</td>\n",
       "      <td>&amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME : &amp;NAME ...</td>\n",
       "      <td>SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME : &amp;NAME ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, 25 Mar 2003 02:19:55 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>... Lock in on low rates - &amp;NAME &amp;NUM - more...</td>\n",
       "      <td>... Lock in on low rates - &amp;NAME &amp;NUM - more...</td>\n",
       "      <td>text/html;</td>\n",
       "      <td>&amp;NAME If you wish to unsubscribe from &amp;NAME ...</td>\n",
       "      <td>&amp;NAME If you wish to unsubscribe from &amp;NAME ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 4 Dec 2002 17:14:13 -0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>&amp;NAME applications</td>\n",
       "      <td>&amp;NAME applications</td>\n",
       "      <td>text/plain; charset=\"us-ascii\"</td>\n",
       "      <td>The Lab 's Industrial Supporters ' &amp;NAME &amp;NA...</td>\n",
       "      <td>The Lab 's Industrial Supporters ' &amp;NAME &amp;NA...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri, 22 Nov 2002 09:44:23 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>COPY ANY &amp;NAME TO A &amp;NAME</td>\n",
       "      <td>COPY ANY &amp;NAME TO A &amp;NAME</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon, 3 Feb 2003 21:22:25 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>\\n</td>\n",
       "      <td>NEW / / COPY ANY &amp;NAME TO &amp;NAME</td>\n",
       "      <td>NEW / / COPY ANY &amp;NAME TO &amp;NAME</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 727 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date     from       to  \\\n",
       "0   Tue, 10 Sep 2002 13:24:26 -1700      net      edu    \n",
       "1   Tue, 25 Mar 2003 02:19:55 -0800      com    ac.uk    \n",
       "2    Wed, 4 Dec 2002 17:14:13 -0000    ac.uk    ac.uk    \n",
       "3   Fri, 22 Nov 2002 09:44:23 -0800      com    ac.uk    \n",
       "4    Mon, 3 Feb 2003 21:22:25 -0800      com        \\n   \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0               &NAME &NAME Watch , ' &NAME ' &NAME    \n",
       "1    ... Lock in on low rates - &NAME &NUM - more...   \n",
       "2                                &NAME applications    \n",
       "3                         COPY ANY &NAME TO A &NAME    \n",
       "4                   NEW / / COPY ANY &NAME TO &NAME    \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0               &NAME &NAME Watch , ' &NAME ' &NAME    \n",
       "1    ... Lock in on low rates - &NAME &NUM - more...   \n",
       "2                                &NAME applications    \n",
       "3                         COPY ANY &NAME TO A &NAME    \n",
       "4                   NEW / / COPY ANY &NAME TO &NAME    \n",
       "\n",
       "                         content-type  \\\n",
       "0    text/html; charset=\"iso-8859-1\"    \n",
       "1                         text/html;    \n",
       "2     text/plain; charset=\"us-ascii\"    \n",
       "3   text/plain; charset=\"iso-8859-1\"    \n",
       "4   text/plain; charset=\"iso-8859-1\"    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    SPECIAL ALERT The &NAME &NAME &NAME : &NAME ...   \n",
       "1    &NAME If you wish to unsubscribe from &NAME ...   \n",
       "2    The Lab 's Industrial Supporters ' &NAME &NA...   \n",
       "3    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...   \n",
       "4    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...   \n",
       "\n",
       "                                 message_body_normal message_body_embedded_0  \\\n",
       "0    SPECIAL ALERT The &NAME &NAME &NAME : &NAME ...                     nan   \n",
       "1    &NAME If you wish to unsubscribe from &NAME ...                     nan   \n",
       "2    The Lab 's Industrial Supporters ' &NAME &NA...                     nan   \n",
       "3    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...                     nan   \n",
       "4    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...                     nan   \n",
       "\n",
       "  message_body_embedded_1  ... mean_tf valuable_tf invit_tf committee_tf  \\\n",
       "0                     nan  ...       0           0        0            0   \n",
       "1                     nan  ...       0           0        0            0   \n",
       "2                     nan  ...       0           0        0            2   \n",
       "3                     nan  ...       0           0        0            0   \n",
       "4                     nan  ...       0           0        0            0   \n",
       "\n",
       "  tin_tf work_tf sci_tf cult_tf link_tf 7th_tf  \n",
       "0      1       0      0       0       0      0  \n",
       "1      0       0      0       0       0      0  \n",
       "2      0       0      0       0       0      0  \n",
       "3      0       0      0       0       0      0  \n",
       "4      0       0      0       0       0      0  \n",
       "\n",
       "[5 rows x 727 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_adap = df_adap.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_tf_adap[token + '_tf'] = df_tf_adap.subject_body.str.count(token)\n",
    "df_tf_adap[col_names_tf] = df_tf_adap[col_names_tf].fillna(0)\n",
    "df_tf_adap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_adap = df_tf_adap[list(col_names_tf) + ['spam']].dropna()\n",
    "df_tf_adap = df_tf_adap.astype(int)\n",
    "df_tf_adap.to_csv(\"data_tf/data_\" + str(nb_words) + \".adap\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract boolean attributes for the best tokens retained and save the corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Qq6OgY7eUVDA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_embedded_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>valuable</th>\n",
       "      <th>invit</th>\n",
       "      <th>committee</th>\n",
       "      <th>tin</th>\n",
       "      <th>work</th>\n",
       "      <th>sci</th>\n",
       "      <th>cult</th>\n",
       "      <th>link</th>\n",
       "      <th>7th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Sep 2002 13:24:26 -1700</td>\n",
       "      <td>net</td>\n",
       "      <td>True</td>\n",
       "      <td>&amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME</td>\n",
       "      <td>&amp;NAME &amp;NAME Watch , ' &amp;NAME ' &amp;NAME</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME : &amp;NAME ...</td>\n",
       "      <td>SPECIAL ALERT The &amp;NAME &amp;NAME &amp;NAME : &amp;NAME ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue, 25 Mar 2003 02:19:55 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>... Lock in on low rates - &amp;NAME &amp;NUM - more...</td>\n",
       "      <td>... Lock in on low rates - &amp;NAME &amp;NUM - more...</td>\n",
       "      <td>text/html;</td>\n",
       "      <td>&amp;NAME If you wish to unsubscribe from &amp;NAME ...</td>\n",
       "      <td>&amp;NAME If you wish to unsubscribe from &amp;NAME ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed, 4 Dec 2002 17:14:13 -0000</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>True</td>\n",
       "      <td>&amp;NAME applications</td>\n",
       "      <td>&amp;NAME applications</td>\n",
       "      <td>text/plain; charset=\"us-ascii\"</td>\n",
       "      <td>The Lab 's Industrial Supporters ' &amp;NAME &amp;NA...</td>\n",
       "      <td>The Lab 's Industrial Supporters ' &amp;NAME &amp;NA...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri, 22 Nov 2002 09:44:23 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>COPY ANY &amp;NAME TO A &amp;NAME</td>\n",
       "      <td>COPY ANY &amp;NAME TO A &amp;NAME</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mon, 3 Feb 2003 21:22:25 -0800</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>NEW / / COPY ANY &amp;NAME TO &amp;NAME</td>\n",
       "      <td>NEW / / COPY ANY &amp;NAME TO &amp;NAME</td>\n",
       "      <td>text/plain; charset=\"iso-8859-1\"</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>UNSUBSCRIBE AT THE BOTTOM  Dear &amp;NAME / Memb...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 726 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date     from    to  \\\n",
       "0   Tue, 10 Sep 2002 13:24:26 -1700      net   True   \n",
       "1   Tue, 25 Mar 2003 02:19:55 -0800      com   True   \n",
       "2    Wed, 4 Dec 2002 17:14:13 -0000    ac.uk   True   \n",
       "3   Fri, 22 Nov 2002 09:44:23 -0800      com   True   \n",
       "4    Mon, 3 Feb 2003 21:22:25 -0800      com   True   \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0               &NAME &NAME Watch , ' &NAME ' &NAME    \n",
       "1    ... Lock in on low rates - &NAME &NUM - more...   \n",
       "2                                &NAME applications    \n",
       "3                         COPY ANY &NAME TO A &NAME    \n",
       "4                   NEW / / COPY ANY &NAME TO &NAME    \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0               &NAME &NAME Watch , ' &NAME ' &NAME    \n",
       "1    ... Lock in on low rates - &NAME &NUM - more...   \n",
       "2                                &NAME applications    \n",
       "3                         COPY ANY &NAME TO A &NAME    \n",
       "4                   NEW / / COPY ANY &NAME TO &NAME    \n",
       "\n",
       "                         content-type  \\\n",
       "0    text/html; charset=\"iso-8859-1\"    \n",
       "1                         text/html;    \n",
       "2     text/plain; charset=\"us-ascii\"    \n",
       "3   text/plain; charset=\"iso-8859-1\"    \n",
       "4   text/plain; charset=\"iso-8859-1\"    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    SPECIAL ALERT The &NAME &NAME &NAME : &NAME ...   \n",
       "1    &NAME If you wish to unsubscribe from &NAME ...   \n",
       "2    The Lab 's Industrial Supporters ' &NAME &NA...   \n",
       "3    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...   \n",
       "4    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...   \n",
       "\n",
       "                                 message_body_normal message_body_embedded_0  \\\n",
       "0    SPECIAL ALERT The &NAME &NAME &NAME : &NAME ...                     nan   \n",
       "1    &NAME If you wish to unsubscribe from &NAME ...                     nan   \n",
       "2    The Lab 's Industrial Supporters ' &NAME &NA...                     nan   \n",
       "3    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...                     nan   \n",
       "4    UNSUBSCRIBE AT THE BOTTOM  Dear &NAME / Memb...                     nan   \n",
       "\n",
       "  message_body_embedded_1  ...   mean valuable  invit committee    tin   work  \\\n",
       "0                     nan  ...  False    False  False     False   True  False   \n",
       "1                     nan  ...  False    False  False     False  False  False   \n",
       "2                     nan  ...  False    False  False      True  False  False   \n",
       "3                     nan  ...  False    False  False     False  False  False   \n",
       "4                     nan  ...  False    False  False     False  False  False   \n",
       "\n",
       "     sci   cult   link    7th  \n",
       "0  False  False  False  False  \n",
       "1  False  False  False  False  \n",
       "2  False  False  False  False  \n",
       "3  False  False  False  False  \n",
       "4  False  False  False  False  \n",
       "\n",
       "[5 rows x 726 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timbl_adap = df_adap.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_timbl_adap[token] = df_timbl_adap.subject_body.str.contains(token)\n",
    "df_timbl_adap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "TaQNwAnXUVDA"
   },
   "outputs": [],
   "source": [
    "df_timbl_adap = df_timbl_adap[list(vocab_best_ig) + ['spam']]\n",
    "df_timbl_adap = df_timbl_adap.astype(int)\n",
    "df_timbl_adap.to_csv(\"data_timbl/data_\" + str(nb_words) + \".adap\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTZF4Gw6UVC_"
   },
   "source": [
    "## Test set pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load and extract data from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "PamDsu76UVC_"
   },
   "outputs": [],
   "source": [
    "df_gen_test = xml_to_df(\"GenSpam/test_GEN.ems\")\n",
    "df_gen_test['spam'] = False\n",
    "df_spam_test = xml_to_df(\"GenSpam/test_SPAM.ems\")\n",
    "df_spam_test['spam'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ycoryZQcUVC_"
   },
   "outputs": [],
   "source": [
    "df_test = df_gen_test.append(df_spam_test)\n",
    "df_test = df_test.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "f2PQQDwLUVDA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_normal_1</th>\n",
       "      <th>...</th>\n",
       "      <th>message_body_embedded_4</th>\n",
       "      <th>message_body_embedded_5</th>\n",
       "      <th>message_body_embedded_6</th>\n",
       "      <th>message_body_embedded_7</th>\n",
       "      <th>message_body_normal_2</th>\n",
       "      <th>message_body_normal_3</th>\n",
       "      <th>message_body_normal_4</th>\n",
       "      <th>message_body_normal_5</th>\n",
       "      <th>spam</th>\n",
       "      <th>message_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Jun 2003 21:00:26 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ Re : results \\n</td>\n",
       "      <td>\\n \\n\\n^ Re : results \\n</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>\\n\\n^ Is n't it always the case ... ! \\n^ Che...</td>\n",
       "      <td>\\n \\n\\n^ Is n't it always the case ... ! \\n^ C...</td>\n",
       "      <td>\\n\\n^ too good to be true ... see you next we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 Jun 2003 20:20:40 -0000</td>\n",
       "      <td>email</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ Easy Mortgage Shopping , Apply Free , A...</td>\n",
       "      <td>\\n \\n\\n^ Easy Mortgage Shopping , Apply Free ,...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>\\n\\n^ The following message was sent to you a...</td>\n",
       "      <td>\\n \\n\\n^ The following message was sent to you...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 18 Feb 2003 02:53:45 -0500</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ hranostajovu mutarent ted.briscoe Come ...</td>\n",
       "      <td>\\n \\n\\n^ hranostajovu mutarent ted.briscoe Com...</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>\\n\\n^ ted.briscoe \\n^ On January 1st &amp;NUM , t...</td>\n",
       "      <td>\\n \\n\\n^ ted.briscoe \\n^ On January 1st &amp;NUM ,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu, 27 Feb 2003 19:53:11 +0100</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk ac.uk</td>\n",
       "      <td>\\n\\n^ Opinion Polls by &amp;NAME : Your opinion i...</td>\n",
       "      <td>\\n \\n\\n^ Opinion Polls by &amp;NAME : Your opinion...</td>\n",
       "      <td>text/plain; charset=iso-8859-1</td>\n",
       "      <td>\\n\\n^ Dear Sir or Madam , \\n^ Your opinion is...</td>\n",
       "      <td>\\n \\n\\n^ Dear Sir or Madam , \\n^ Your opinion ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun, 25 May 2003 15:46:27 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>\\n\\n^ Re : background music \\n</td>\n",
       "      <td>\\n \\n\\n^ Re : background music \\n</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>\\n\\n^ &amp;NAME , did you get returned all the em...</td>\n",
       "      <td>\\n \\n\\n^ &amp;NAME , did you get returned all the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      date     from             to  \\\n",
       "0   Tue, 10 Jun 2003 21:00:26 +0100 (BST)    ac.uk          ac.uk    \n",
       "1              24 Jun 2003 20:20:40 -0000    email          ac.uk    \n",
       "2         Tue, 18 Feb 2003 02:53:45 -0500      com          ac.uk    \n",
       "3         Thu, 27 Feb 2003 19:53:11 +0100      com    ac.uk ac.uk    \n",
       "4   Sun, 25 May 2003 15:46:27 +0100 (BST)    ac.uk          ac.uk    \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0                              \\n\\n^ Re : results \\n   \n",
       "1   \\n\\n^ Easy Mortgage Shopping , Apply Free , A...   \n",
       "2   \\n\\n^ hranostajovu mutarent ted.briscoe Come ...   \n",
       "3   \\n\\n^ Opinion Polls by &NAME : Your opinion i...   \n",
       "4                     \\n\\n^ Re : background music \\n   \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0                           \\n \\n\\n^ Re : results \\n   \n",
       "1  \\n \\n\\n^ Easy Mortgage Shopping , Apply Free ,...   \n",
       "2  \\n \\n\\n^ hranostajovu mutarent ted.briscoe Com...   \n",
       "3  \\n \\n\\n^ Opinion Polls by &NAME : Your opinion...   \n",
       "4                  \\n \\n\\n^ Re : background music \\n   \n",
       "\n",
       "                        content-type  \\\n",
       "0      TEXT/PLAIN; charset=US-ASCII    \n",
       "1     text/html; charset=\"us-ascii\"    \n",
       "2   text/html; charset=\"iso-8859-1\"    \n",
       "3    text/plain; charset=iso-8859-1    \n",
       "4      TEXT/PLAIN; charset=US-ASCII    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0   \\n\\n^ Is n't it always the case ... ! \\n^ Che...   \n",
       "1   \\n\\n^ The following message was sent to you a...   \n",
       "2   \\n\\n^ ted.briscoe \\n^ On January 1st &NUM , t...   \n",
       "3   \\n\\n^ Dear Sir or Madam , \\n^ Your opinion is...   \n",
       "4   \\n\\n^ &NAME , did you get returned all the em...   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0  \\n \\n\\n^ Is n't it always the case ... ! \\n^ C...   \n",
       "1  \\n \\n\\n^ The following message was sent to you...   \n",
       "2  \\n \\n\\n^ ted.briscoe \\n^ On January 1st &NUM ,...   \n",
       "3  \\n \\n\\n^ Dear Sir or Madam , \\n^ Your opinion ...   \n",
       "4  \\n \\n\\n^ &NAME , did you get returned all the ...   \n",
       "\n",
       "                             message_body_embedded_0 message_body_normal_1  \\\n",
       "0   \\n\\n^ too good to be true ... see you next we...                   NaN   \n",
       "1                                                NaN                   NaN   \n",
       "2                                                NaN                   NaN   \n",
       "3                                                NaN                   NaN   \n",
       "4                                                NaN                   NaN   \n",
       "\n",
       "   ... message_body_embedded_4 message_body_embedded_5  \\\n",
       "0  ...                     NaN                     NaN   \n",
       "1  ...                     NaN                     NaN   \n",
       "2  ...                     NaN                     NaN   \n",
       "3  ...                     NaN                     NaN   \n",
       "4  ...                     NaN                     NaN   \n",
       "\n",
       "  message_body_embedded_6 message_body_embedded_7 message_body_normal_2  \\\n",
       "0                     NaN                     NaN                   NaN   \n",
       "1                     NaN                     NaN                   NaN   \n",
       "2                     NaN                     NaN                   NaN   \n",
       "3                     NaN                     NaN                   NaN   \n",
       "4                     NaN                     NaN                   NaN   \n",
       "\n",
       "  message_body_normal_3 message_body_normal_4 message_body_normal_5   spam  \\\n",
       "0                   NaN                   NaN                   NaN  False   \n",
       "1                   NaN                   NaN                   NaN   True   \n",
       "2                   NaN                   NaN                   NaN   True   \n",
       "3                   NaN                   NaN                   NaN   True   \n",
       "4                   NaN                   NaN                   NaN  False   \n",
       "\n",
       "  message_body  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.reset_index().drop(['index'], axis=1)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "N1zoPMk-UVDA"
   },
   "outputs": [],
   "source": [
    "filter_col = [col for col in df_test if col.startswith('message_body') or col.startswith('subject_normal')]\n",
    "for col in filter_col:\n",
    "    df_test[col] = df_test[col].apply(lambda x: str(x).replace('\\n','').replace('\\r','').replace('^',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QYVa2RYqUVDA"
   },
   "outputs": [],
   "source": [
    "df_test['subject_body'] = df_test['subject_normal_0'] + df_test['message_body_normal_0']\n",
    "df_test['subject_body'] = df_test['subject_body'].str.lower()\n",
    "df_test['subject_body'] = df_test['subject_body'].apply(lambda x: sentence_lemma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract Term-Frequency attributes for the best tokens retained and save the corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_normal_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_tf</th>\n",
       "      <th>valuable_tf</th>\n",
       "      <th>invit_tf</th>\n",
       "      <th>committee_tf</th>\n",
       "      <th>tin_tf</th>\n",
       "      <th>work_tf</th>\n",
       "      <th>sci_tf</th>\n",
       "      <th>cult_tf</th>\n",
       "      <th>link_tf</th>\n",
       "      <th>7th_tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Jun 2003 21:00:26 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>Re : results</td>\n",
       "      <td>Re : results</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>Is n't it always the case ... !  Cheers ,  &amp;...</td>\n",
       "      <td>Is n't it always the case ... !  Cheers ,  &amp;...</td>\n",
       "      <td>too good to be true ... see you next week , ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 Jun 2003 20:20:40 -0000</td>\n",
       "      <td>email</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>Easy Mortgage Shopping , Apply Free , Any Cr...</td>\n",
       "      <td>Easy Mortgage Shopping , Apply Free , Any Cr...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>The following message was sent to you as an ...</td>\n",
       "      <td>The following message was sent to you as an ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 18 Feb 2003 02:53:45 -0500</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>hranostajovu mutarent ted.briscoe Come get it</td>\n",
       "      <td>hranostajovu mutarent ted.briscoe Come get it</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>ted.briscoe  On January 1st &amp;NUM , the Europ...</td>\n",
       "      <td>ted.briscoe  On January 1st &amp;NUM , the Europ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu, 27 Feb 2003 19:53:11 +0100</td>\n",
       "      <td>com</td>\n",
       "      <td>ac.uk ac.uk</td>\n",
       "      <td>Opinion Polls by &amp;NAME : Your opinion is in ...</td>\n",
       "      <td>Opinion Polls by &amp;NAME : Your opinion is in ...</td>\n",
       "      <td>text/plain; charset=iso-8859-1</td>\n",
       "      <td>Dear Sir or Madam ,  Your opinion is in dema...</td>\n",
       "      <td>Dear Sir or Madam ,  Your opinion is in dema...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun, 25 May 2003 15:46:27 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>Re : background music</td>\n",
       "      <td>Re : background music</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>&amp;NAME , did you get returned all the emails ...</td>\n",
       "      <td>&amp;NAME , did you get returned all the emails ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      date     from             to  \\\n",
       "0   Tue, 10 Jun 2003 21:00:26 +0100 (BST)    ac.uk          ac.uk    \n",
       "1              24 Jun 2003 20:20:40 -0000    email          ac.uk    \n",
       "2         Tue, 18 Feb 2003 02:53:45 -0500      com          ac.uk    \n",
       "3         Thu, 27 Feb 2003 19:53:11 +0100      com    ac.uk ac.uk    \n",
       "4   Sun, 25 May 2003 15:46:27 +0100 (BST)    ac.uk          ac.uk    \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0                                      Re : results    \n",
       "1    Easy Mortgage Shopping , Apply Free , Any Cr...   \n",
       "2     hranostajovu mutarent ted.briscoe Come get it    \n",
       "3    Opinion Polls by &NAME : Your opinion is in ...   \n",
       "4                             Re : background music    \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0                                      Re : results    \n",
       "1    Easy Mortgage Shopping , Apply Free , Any Cr...   \n",
       "2     hranostajovu mutarent ted.briscoe Come get it    \n",
       "3    Opinion Polls by &NAME : Your opinion is in ...   \n",
       "4                             Re : background music    \n",
       "\n",
       "                        content-type  \\\n",
       "0      TEXT/PLAIN; charset=US-ASCII    \n",
       "1     text/html; charset=\"us-ascii\"    \n",
       "2   text/html; charset=\"iso-8859-1\"    \n",
       "3    text/plain; charset=iso-8859-1    \n",
       "4      TEXT/PLAIN; charset=US-ASCII    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    Is n't it always the case ... !  Cheers ,  &...   \n",
       "1    The following message was sent to you as an ...   \n",
       "2    ted.briscoe  On January 1st &NUM , the Europ...   \n",
       "3    Dear Sir or Madam ,  Your opinion is in dema...   \n",
       "4    &NAME , did you get returned all the emails ...   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0    Is n't it always the case ... !  Cheers ,  &...   \n",
       "1    The following message was sent to you as an ...   \n",
       "2    ted.briscoe  On January 1st &NUM , the Europ...   \n",
       "3    Dear Sir or Madam ,  Your opinion is in dema...   \n",
       "4    &NAME , did you get returned all the emails ...   \n",
       "\n",
       "                             message_body_embedded_0 message_body_normal_1  \\\n",
       "0    too good to be true ... see you next week , ...                   nan   \n",
       "1                                                nan                   nan   \n",
       "2                                                nan                   nan   \n",
       "3                                                nan                   nan   \n",
       "4                                                nan                   nan   \n",
       "\n",
       "   ... mean_tf valuable_tf invit_tf committee_tf tin_tf work_tf sci_tf  \\\n",
       "0  ...       0           0        0            0      0       0      0   \n",
       "1  ...       0           1        0            0      1       0      0   \n",
       "2  ...       1           0        0            0      0       0      0   \n",
       "3  ...       0           1        1            0      1       0      0   \n",
       "4  ...       0           0        0            0      0       0      0   \n",
       "\n",
       "  cult_tf link_tf 7th_tf  \n",
       "0       0       0      0  \n",
       "1       0       0      0  \n",
       "2       0       0      0  \n",
       "3       0       1      0  \n",
       "4       0       0      0  \n",
       "\n",
       "[5 rows x 724 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_test = df_test.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_tf_test[token + '_tf'] = df_tf_test.subject_body.str.count(token)\n",
    "df_tf_test[col_names_tf] = df_tf_test[col_names_tf].fillna(0)\n",
    "df_tf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_test = df_tf_test[list(col_names_tf) + ['spam']].dropna()\n",
    "df_tf_test = df_tf_test.astype(int)\n",
    "df_tf_test.to_csv(\"data_tf/data_\" + str(nb_words) + \".test\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract boolean attributes for the best tokens retained and save the corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Qq6OgY7eUVDA"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject_normal_0</th>\n",
       "      <th>subject_normal</th>\n",
       "      <th>content-type</th>\n",
       "      <th>message_body_normal_0</th>\n",
       "      <th>message_body_normal</th>\n",
       "      <th>message_body_embedded_0</th>\n",
       "      <th>message_body_normal_1</th>\n",
       "      <th>...</th>\n",
       "      <th>mean</th>\n",
       "      <th>valuable</th>\n",
       "      <th>invit</th>\n",
       "      <th>committee</th>\n",
       "      <th>tin</th>\n",
       "      <th>work</th>\n",
       "      <th>sci</th>\n",
       "      <th>cult</th>\n",
       "      <th>link</th>\n",
       "      <th>7th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue, 10 Jun 2003 21:00:26 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>False</td>\n",
       "      <td>Re : results</td>\n",
       "      <td>Re : results</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>Is n't it always the case ... !  Cheers ,  &amp;...</td>\n",
       "      <td>Is n't it always the case ... !  Cheers ,  &amp;...</td>\n",
       "      <td>too good to be true ... see you next week , ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 Jun 2003 20:20:40 -0000</td>\n",
       "      <td>email</td>\n",
       "      <td>True</td>\n",
       "      <td>Easy Mortgage Shopping , Apply Free , Any Cr...</td>\n",
       "      <td>Easy Mortgage Shopping , Apply Free , Any Cr...</td>\n",
       "      <td>text/html; charset=\"us-ascii\"</td>\n",
       "      <td>The following message was sent to you as an ...</td>\n",
       "      <td>The following message was sent to you as an ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue, 18 Feb 2003 02:53:45 -0500</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>hranostajovu mutarent ted.briscoe Come get it</td>\n",
       "      <td>hranostajovu mutarent ted.briscoe Come get it</td>\n",
       "      <td>text/html; charset=\"iso-8859-1\"</td>\n",
       "      <td>ted.briscoe  On January 1st &amp;NUM , the Europ...</td>\n",
       "      <td>ted.briscoe  On January 1st &amp;NUM , the Europ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thu, 27 Feb 2003 19:53:11 +0100</td>\n",
       "      <td>com</td>\n",
       "      <td>True</td>\n",
       "      <td>Opinion Polls by &amp;NAME : Your opinion is in ...</td>\n",
       "      <td>Opinion Polls by &amp;NAME : Your opinion is in ...</td>\n",
       "      <td>text/plain; charset=iso-8859-1</td>\n",
       "      <td>Dear Sir or Madam ,  Your opinion is in dema...</td>\n",
       "      <td>Dear Sir or Madam ,  Your opinion is in dema...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun, 25 May 2003 15:46:27 +0100 (BST)</td>\n",
       "      <td>ac.uk</td>\n",
       "      <td>True</td>\n",
       "      <td>Re : background music</td>\n",
       "      <td>Re : background music</td>\n",
       "      <td>TEXT/PLAIN; charset=US-ASCII</td>\n",
       "      <td>&amp;NAME , did you get returned all the emails ...</td>\n",
       "      <td>&amp;NAME , did you get returned all the emails ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      date     from     to  \\\n",
       "0   Tue, 10 Jun 2003 21:00:26 +0100 (BST)    ac.uk   False   \n",
       "1              24 Jun 2003 20:20:40 -0000    email    True   \n",
       "2         Tue, 18 Feb 2003 02:53:45 -0500      com    True   \n",
       "3         Thu, 27 Feb 2003 19:53:11 +0100      com    True   \n",
       "4   Sun, 25 May 2003 15:46:27 +0100 (BST)    ac.uk    True   \n",
       "\n",
       "                                    subject_normal_0  \\\n",
       "0                                      Re : results    \n",
       "1    Easy Mortgage Shopping , Apply Free , Any Cr...   \n",
       "2     hranostajovu mutarent ted.briscoe Come get it    \n",
       "3    Opinion Polls by &NAME : Your opinion is in ...   \n",
       "4                             Re : background music    \n",
       "\n",
       "                                      subject_normal  \\\n",
       "0                                      Re : results    \n",
       "1    Easy Mortgage Shopping , Apply Free , Any Cr...   \n",
       "2     hranostajovu mutarent ted.briscoe Come get it    \n",
       "3    Opinion Polls by &NAME : Your opinion is in ...   \n",
       "4                             Re : background music    \n",
       "\n",
       "                        content-type  \\\n",
       "0      TEXT/PLAIN; charset=US-ASCII    \n",
       "1     text/html; charset=\"us-ascii\"    \n",
       "2   text/html; charset=\"iso-8859-1\"    \n",
       "3    text/plain; charset=iso-8859-1    \n",
       "4      TEXT/PLAIN; charset=US-ASCII    \n",
       "\n",
       "                               message_body_normal_0  \\\n",
       "0    Is n't it always the case ... !  Cheers ,  &...   \n",
       "1    The following message was sent to you as an ...   \n",
       "2    ted.briscoe  On January 1st &NUM , the Europ...   \n",
       "3    Dear Sir or Madam ,  Your opinion is in dema...   \n",
       "4    &NAME , did you get returned all the emails ...   \n",
       "\n",
       "                                 message_body_normal  \\\n",
       "0    Is n't it always the case ... !  Cheers ,  &...   \n",
       "1    The following message was sent to you as an ...   \n",
       "2    ted.briscoe  On January 1st &NUM , the Europ...   \n",
       "3    Dear Sir or Madam ,  Your opinion is in dema...   \n",
       "4    &NAME , did you get returned all the emails ...   \n",
       "\n",
       "                             message_body_embedded_0 message_body_normal_1  \\\n",
       "0    too good to be true ... see you next week , ...                   nan   \n",
       "1                                                nan                   nan   \n",
       "2                                                nan                   nan   \n",
       "3                                                nan                   nan   \n",
       "4                                                nan                   nan   \n",
       "\n",
       "   ...   mean valuable  invit committee    tin   work    sci   cult   link  \\\n",
       "0  ...  False    False  False     False  False  False  False  False  False   \n",
       "1  ...  False     True  False     False   True  False  False  False  False   \n",
       "2  ...   True    False  False     False  False  False  False  False  False   \n",
       "3  ...  False     True   True     False   True  False  False  False   True   \n",
       "4  ...  False    False  False     False  False  False  False  False  False   \n",
       "\n",
       "     7th  \n",
       "0  False  \n",
       "1  False  \n",
       "2  False  \n",
       "3  False  \n",
       "4  False  \n",
       "\n",
       "[5 rows x 723 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_timbl_test = df_test.copy()\n",
    "for token in vocab_best_ig:\n",
    "    df_timbl_test[token] = df_timbl_test.subject_body.str.contains(token)\n",
    "df_timbl_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "TaQNwAnXUVDA"
   },
   "outputs": [],
   "source": [
    "df_timbl_test = df_timbl_test[list(vocab_best_ig)[:nb_words] + ['spam']]\n",
    "df_timbl_test = df_timbl_test.astype(int)\n",
    "df_timbl_test.to_csv(\"data_timbl/data_\" + str(nb_words) + \".test\", sep=',', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-WPUMalUVDB"
   },
   "source": [
    "## Naive Bayes models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names correspond to the tokens with best information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = list(vocab_best_ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load all dataframes with Term-Frequency attributes previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_train = pd.read_csv('data_tf/data_700.train')\n",
    "df_tf_train.columns = col_names + ['spam']\n",
    "df_tf_adap = pd.read_csv('data_tf/data_700.adap')\n",
    "df_tf_adap.columns = col_names + ['spam']\n",
    "df_tf_test = pd.read_csv('data_tf/data_700.test')\n",
    "df_tf_test.columns = col_names + ['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new dataframe with normalized Term-Frequency attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_train_val = df_tf_train.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "df_tf_train_norm = min_max_scaler.fit_transform(df_tf_train_val)\n",
    "df_tf_train_norm = pd.DataFrame(df_tf_train_norm)\n",
    "df_tf_train_norm.columns = col_names + ['spam']\n",
    "\n",
    "df_tf_adap_norm = pd.DataFrame(min_max_scaler.transform(df_tf_adap.values))\n",
    "df_tf_adap_norm.columns = col_names + ['spam']\n",
    "\n",
    "df_tf_test_norm = pd.DataFrame(min_max_scaler.transform(df_tf_test.values))\n",
    "df_tf_test_norm.columns = col_names + ['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load all dataframes with Boolean attributes previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timbl_train = pd.read_csv('data_timbl/data_700.train')\n",
    "df_timbl_train.columns = col_names + ['spam']\n",
    "df_timbl_adap = pd.read_csv('data_timbl/data_700.adap')\n",
    "df_timbl_adap.columns = col_names + ['spam']\n",
    "df_timbl_test = pd.read_csv('data_timbl/data_700.test')\n",
    "df_timbl_test.columns = col_names + ['spam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to apply different Naive Bayes models to our data, and compute different metrics (precision, recall, F1-score, and AUC) with the train and **adaptation** sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "umc5iYCnUVDB"
   },
   "outputs": [],
   "source": [
    "model_names = [\"Multinomial NB TF\", \"Multinomial NB Boolean\", \"Multivariate Bernoulli NB\", \"Gaussian NB Boolean\", \"Gaussian NB Normalized\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    # we consider different numbers of attributes\n",
    "    for nb_words in range(50,750,50):\n",
    "        # model and data selection\n",
    "        if model_name == \"Multinomial NB TF\":\n",
    "            model = MultinomialNB()\n",
    "            df_model_train = df_tf_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_adap = df_tf_adap[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Multinomial NB Boolean\":\n",
    "            model = MultinomialNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_adap = df_timbl_adap[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Multivariate Bernoulli NB\":\n",
    "            model = BernoulliNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_adap = df_timbl_adap[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Gaussian NB Boolean\":\n",
    "            model = GaussianNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_adap = df_timbl_adap[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Gaussian NB Normalized\":\n",
    "            model = GaussianNB()\n",
    "            df_model_train = df_tf_train_norm[col_names[:nb_words] + ['spam']]\n",
    "            df_model_adap = df_tf_adap_norm[col_names[:nb_words] + ['spam']]\n",
    "\n",
    "        # we create train, adapatation and test sets for models\n",
    "        X_train = df_model_train.drop('spam', axis=1)\n",
    "        Y_train = df_model_train['spam']\n",
    "        X_adap = df_model_adap.drop('spam', axis=1)\n",
    "        Y_adap = df_model_adap['spam']\n",
    "\n",
    "        # we fit models and make predictions\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_adap)\n",
    "\n",
    "        # we compute different metrics about predictions\n",
    "        precision = metrics.precision_score(Y_adap, Y_pred)\n",
    "        recall = metrics.recall_score(Y_adap, Y_pred)\n",
    "        f1_score = metrics.f1_score(Y_adap, Y_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y_adap, Y_pred)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        # we store results in a dataframe\n",
    "        results = pd.DataFrame([[model_name, nb_words, precision, recall, f1_score, auc]], columns=['model_name', 'nb_words', 'precision', 'recall', 'f1_score', 'auc'])\n",
    "        df_save = pd.read_csv(\"nb_results.csv\")\n",
    "        df_save = df_save.append(results)\n",
    "        df_save.to_csv(\"nb_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop to apply different Naive Bayes models to our data, and compute different metrics (precision, recall, F1-score, and AUC) with the train and **test** sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "umc5iYCnUVDB"
   },
   "outputs": [],
   "source": [
    "model_names = [\"Multinomial NB TF\", \"Multinomial NB Boolean\", \"Multivariate Bernoulli NB\", \"Gaussian NB Boolean\", \"Gaussian NB Normalized\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    # we consider different numbers of attributes\n",
    "    for nb_words in range(50,750,50):\n",
    "        # model and data selection\n",
    "        if model_name == \"Multinomial NB TF\":\n",
    "            model = MultinomialNB()\n",
    "            df_model_train = df_tf_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_test = df_tf_test[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Multinomial NB Boolean\":\n",
    "            model = MultinomialNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_test = df_timbl_test[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Multivariate Bernoulli NB\":\n",
    "            model = BernoulliNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_test = df_timbl_test[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Gaussian NB Boolean\":\n",
    "            model = GaussianNB()\n",
    "            df_model_train = df_timbl_train[col_names[:nb_words] + ['spam']]\n",
    "            df_model_test = df_timbl_test[col_names[:nb_words] + ['spam']]\n",
    "        elif model_name == \"Gaussian NB Normalized\":\n",
    "            model = GaussianNB()\n",
    "            df_model_train = df_tf_train_norm[col_names[:nb_words] + ['spam']]\n",
    "            df_model_test = df_tf_test_norm[col_names[:nb_words] + ['spam']]\n",
    "\n",
    "        # we create train, adapatation and test sets for models\n",
    "        X_train = df_model_train.drop('spam', axis=1)\n",
    "        Y_train = df_model_train['spam']\n",
    "        X_test = df_model_test.drop('spam', axis=1)\n",
    "        Y_test = df_model_test['spam']\n",
    "\n",
    "        # we fit models and make predictions\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "\n",
    "        # we compute different metrics about predictions\n",
    "        precision = metrics.precision_score(Y_test, Y_pred)\n",
    "        recall = metrics.recall_score(Y_test, Y_pred)\n",
    "        f1_score = metrics.f1_score(Y_test, Y_pred)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred)\n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "        # we store results in a dataframe\n",
    "        results = pd.DataFrame([[model_name + \" Test\", nb_words, precision, recall, f1_score, auc]], columns=['model_name', 'nb_words', 'precision', 'recall', 'f1_score', 'auc'])\n",
    "        df_save = pd.read_csv(\"nb_results.csv\")\n",
    "        df_save = df_save.append(results)\n",
    "        df_save.to_csv(\"nb_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "spam_filtering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
